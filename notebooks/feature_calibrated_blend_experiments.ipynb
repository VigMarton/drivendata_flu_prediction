{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature-engineered + isotonic-calibrated blend\n",
        "\n",
        "Goal: add survey-structure features, train LGBM + CatBoost, then isotonic-calibrate\n",
        "and blend with the same weights as the base blend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "ROOT = Path(\"..\").resolve()\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "RUNS_DIR = ROOT / \"runs\"\n",
        "\n",
        "X_train = pd.read_csv(DATA_DIR / \"training_set_features.csv\", index_col=\"respondent_id\")\n",
        "y = pd.read_csv(DATA_DIR / \"training_set_labels.csv\", index_col=\"respondent_id\")\n",
        "X_test = pd.read_csv(DATA_DIR / \"test_set_features.csv\", index_col=\"respondent_id\")\n",
        "\n",
        "strat = (2 * y[\"h1n1_vaccine\"].astype(int) + y[\"seasonal_vaccine\"].astype(int)).values\n",
        "\n",
        "\n",
        "def auc_scores(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> dict:\n",
        "    scores = {c: roc_auc_score(y_true[c], y_pred[c]) for c in y_true.columns}\n",
        "    scores[\"mean_auc\"] = float(np.mean(list(scores.values())))\n",
        "    return scores\n",
        "\n",
        "\n",
        "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    behavior_cols = [\n",
        "        \"behavioral_antiviral_meds\",\n",
        "        \"behavioral_avoidance\",\n",
        "        \"behavioral_face_mask\",\n",
        "        \"behavioral_wash_hands\",\n",
        "        \"behavioral_large_gatherings\",\n",
        "        \"behavioral_outside_home\",\n",
        "        \"behavioral_touch_face\",\n",
        "    ]\n",
        "    out[\"behavioral_sum\"] = out[behavior_cols].sum(axis=1, min_count=1)\n",
        "\n",
        "    out[\"opinion_effective_gap\"] = (\n",
        "        out[\"opinion_h1n1_vacc_effective\"] - out[\"opinion_seas_vacc_effective\"]\n",
        "    )\n",
        "    out[\"opinion_risk_gap\"] = out[\"opinion_h1n1_risk\"] - out[\"opinion_seas_risk\"]\n",
        "    out[\"opinion_sick_gap\"] = (\n",
        "        out[\"opinion_h1n1_sick_from_vacc\"] - out[\"opinion_seas_sick_from_vacc\"]\n",
        "    )\n",
        "    out[\"doctor_recc_any\"] = (\n",
        "        (out[\"doctor_recc_h1n1\"] == 1) | (out[\"doctor_recc_seasonal\"] == 1)\n",
        "    ).astype(float)\n",
        "    return out\n",
        "\n",
        "\n",
        "X_train_fe = build_features(X_train)\n",
        "X_test_fe = build_features(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train LightGBM + CatBoost (OOF + test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_lgbm(X: pd.DataFrame) -> tuple[pd.DataFrame, list[str]]:\n",
        "    cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "    Xc = X.copy()\n",
        "    for c in cat_cols:\n",
        "        Xc[c] = Xc[c].astype(\"category\")\n",
        "    return Xc, cat_cols\n",
        "\n",
        "\n",
        "def prepare_catboost(X: pd.DataFrame) -> tuple[pd.DataFrame, list[int]]:\n",
        "    cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "    Xc = X.copy()\n",
        "    for c in cat_cols:\n",
        "        Xc[c] = Xc[c].fillna(\"__MISSING__\").astype(str)\n",
        "    cat_idx = [Xc.columns.get_loc(c) for c in cat_cols]\n",
        "    return Xc, cat_idx\n",
        "\n",
        "\n",
        "def train_oof_lgbm(X: pd.DataFrame, y: pd.DataFrame, X_test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    Xc, cat_cols = prepare_lgbm(X)\n",
        "    X_test_c, _ = prepare_lgbm(X_test)\n",
        "    oof = pd.DataFrame(index=X.index, columns=y.columns, dtype=float)\n",
        "    test_preds = pd.DataFrame(index=X_test.index, columns=y.columns, dtype=float)\n",
        "\n",
        "    params = dict(\n",
        "        objective=\"binary\",\n",
        "        n_estimators=600,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=63,\n",
        "        min_data_in_leaf=50,\n",
        "        feature_fraction=0.8,\n",
        "        bagging_fraction=0.8,\n",
        "        bagging_freq=1,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for tr_idx, va_idx in skf.split(Xc, strat):\n",
        "        X_tr, X_va = Xc.iloc[tr_idx], Xc.iloc[va_idx]\n",
        "        for target in y.columns:\n",
        "            y_tr, y_va = y.iloc[tr_idx][target], y.iloc[va_idx][target]\n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            model.fit(\n",
        "                X_tr,\n",
        "                y_tr,\n",
        "                eval_set=[(X_va, y_va)],\n",
        "                eval_metric=\"auc\",\n",
        "                categorical_feature=cat_cols,\n",
        "                callbacks=[lgb.early_stopping(50, verbose=False)],\n",
        "            )\n",
        "            oof.loc[X_va.index, target] = model.predict_proba(X_va)[:, 1]\n",
        "            test_preds[target] += model.predict_proba(X_test_c)[:, 1] / skf.get_n_splits()\n",
        "\n",
        "    return oof, test_preds\n",
        "\n",
        "\n",
        "def train_oof_catboost(X: pd.DataFrame, y: pd.DataFrame, X_test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    Xc, cat_idx = prepare_catboost(X)\n",
        "    X_test_c, _ = prepare_catboost(X_test)\n",
        "    oof = pd.DataFrame(index=X.index, columns=y.columns, dtype=float)\n",
        "    test_preds = pd.DataFrame(index=X_test.index, columns=y.columns, dtype=float)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for tr_idx, va_idx in skf.split(Xc, strat):\n",
        "        X_tr, X_va = Xc.iloc[tr_idx], Xc.iloc[va_idx]\n",
        "        for target in y.columns:\n",
        "            y_tr, y_va = y.iloc[tr_idx][target], y.iloc[va_idx][target]\n",
        "            model = CatBoostClassifier(\n",
        "                iterations=600,\n",
        "                learning_rate=0.05,\n",
        "                depth=6,\n",
        "                loss_function=\"Logloss\",\n",
        "                eval_metric=\"AUC\",\n",
        "                verbose=False,\n",
        "            )\n",
        "            model.fit(X_tr, y_tr, eval_set=(X_va, y_va), cat_features=cat_idx)\n",
        "            oof.loc[X_va.index, target] = model.predict_proba(X_va)[:, 1]\n",
        "            test_preds[target] += model.predict_proba(X_test_c)[:, 1] / skf.get_n_splits()\n",
        "\n",
        "    return oof, test_preds\n",
        "\n",
        "\n",
        "lgbm_oof_fe, lgbm_test_fe = train_oof_lgbm(X_train_fe, y, X_test_fe)\n",
        "cat_oof_fe, cat_test_fe = train_oof_catboost(X_train_fe, y, X_test_fe)\n",
        "\n",
        "lgbm_scores = auc_scores(y, lgbm_oof_fe)\n",
        "cat_scores = auc_scores(y, cat_oof_fe)\n",
        "lgbm_scores, cat_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Isotonic calibration and blend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _make_calibrator(base_clf, method: str, cv):\n",
        "    try:\n",
        "        return CalibratedClassifierCV(estimator=base_clf, method=method, cv=cv)\n",
        "    except TypeError:\n",
        "        return CalibratedClassifierCV(base_estimator=base_clf, method=method, cv=cv)\n",
        "\n",
        "\n",
        "def calibrate_oof(oof: pd.DataFrame, y: pd.DataFrame, method: str = \"isotonic\") -> pd.DataFrame:\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    out = pd.DataFrame(index=oof.index, columns=oof.columns, dtype=float)\n",
        "    for target in y.columns:\n",
        "        base = oof[[target]].values\n",
        "        y_target = y[target].values\n",
        "        base_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
        "        calib = _make_calibrator(base_clf, method=method, cv=skf)\n",
        "        calib.fit(base, y_target)\n",
        "        out[target] = calib.predict_proba(base)[:, 1]\n",
        "    return out\n",
        "\n",
        "\n",
        "def apply_calibrator_to_test(oof: pd.DataFrame, test: pd.DataFrame, y: pd.DataFrame, method: str = \"isotonic\") -> pd.DataFrame:\n",
        "    out = pd.DataFrame(index=test.index, columns=test.columns, dtype=float)\n",
        "    for target in y.columns:\n",
        "        base_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
        "        calib = _make_calibrator(base_clf, method=method, cv=5)\n",
        "        calib.fit(oof[[target]].values, y[target].values)\n",
        "        out[target] = calib.predict_proba(test[[target]].values)[:, 1]\n",
        "    return out\n",
        "\n",
        "\n",
        "lgbm_iso = calibrate_oof(lgbm_oof_fe, y)\n",
        "cat_iso = calibrate_oof(cat_oof_fe, y)\n",
        "\n",
        "w_lgbm = 0.3885570715220429\n",
        "def blend(a: pd.DataFrame, b: pd.DataFrame, w_a: float) -> pd.DataFrame:\n",
        "    return a * w_a + b * (1.0 - w_a)\n",
        "\n",
        "blend_iso = blend(lgbm_iso, cat_iso, w_lgbm)\n",
        "blend_scores = auc_scores(y, blend_iso)\n",
        "blend_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save outputs and submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = RUNS_DIR / \"calibration_features\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "lgbm_oof_fe.to_csv(out_dir / \"oof_lgbm_fe.csv\", index_label=\"respondent_id\")\n",
        "cat_oof_fe.to_csv(out_dir / \"oof_cat_fe.csv\", index_label=\"respondent_id\")\n",
        "lgbm_test_fe.to_csv(out_dir / \"test_lgbm_fe.csv\", index_label=\"respondent_id\")\n",
        "cat_test_fe.to_csv(out_dir / \"test_cat_fe.csv\", index_label=\"respondent_id\")\n",
        "\n",
        "lgbm_test_iso = apply_calibrator_to_test(lgbm_oof_fe, lgbm_test_fe, y)\n",
        "cat_test_iso = apply_calibrator_to_test(cat_oof_fe, cat_test_fe, y)\n",
        "\n",
        "submission = pd.read_csv(DATA_DIR / \"submission_format.csv\", index_col=\"respondent_id\")\n",
        "submission[[\"h1n1_vaccine\", \"seasonal_vaccine\"]] = blend(lgbm_test_iso, cat_test_iso, w_lgbm)\n",
        "out_path = out_dir / \"submission_isotonic_blend_features.csv\"\n",
        "submission.to_csv(out_path, index_label=\"respondent_id\")\n",
        "\n",
        "out_path"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
